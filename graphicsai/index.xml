<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Graphics and AI on Hamhuo</title>
    <link>http://localhost:1313/graphicsai/</link>
    <description>Recent content in Graphics and AI on Hamhuo</description>
    <generator>Hugo</generator>
    <language>en</language>
    <atom:link href="http://localhost:1313/graphicsai/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>DiffusionModel</title>
      <link>http://localhost:1313/graphicsai/diffusion-model/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/graphicsai/diffusion-model/</guid>
      <description>&lt;h1 id=&#34;生成式aidiffusion-model-原理剖析&#34;&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=ifCDXFdeaaM&amp;amp;t=210s&#34;&gt;生成式AIDiffusion Model 原理剖析&lt;/a&gt;&lt;a class=&#34;td-heading-self-link&#34; href=&#34;#%e7%94%9f%e6%88%90%e5%bc%8faidiffusion-model-%e5%8e%9f%e7%90%86%e5%89%96%e6%9e%90&#34; aria-label=&#34;Heading self-link&#34;&gt;&lt;/a&gt;&lt;/h1&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;WIP&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;p&gt;高斯采样, denoise n次, 产生图片&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/hamhuo-hub/HamPic@img/img/20250403121847531.png&#34; alt=&#34;image.png&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;同一个denosie反复使用, 但是输入噪声的强度不同, 设计一个强度输入&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/hamhuo-hub/HamPic@img/img/20250403122118463.png&#34; alt=&#34;image.png&#34;&gt;&#xA;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/hamhuo-hub/HamPic@img/img/20250403122134092.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;model 内部是预测噪声, 之后减去噪声&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/hamhuo-hub/HamPic@img/img/20250403122251711.png&#34; alt=&#34;image.png&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;为什么不直接输出呢? 产生噪声更简单, 分布简单好训练&lt;/p&gt;&#xA;&lt;p&gt;但是噪声预测怎么训练? 没有pairdata啊&lt;/p&gt;&#xA;&lt;p&gt;那就自己加噪音 - Forward Process&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/hamhuo-hub/HamPic@img/img/20250403122518342.png&#34; alt=&#34;image.png&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/hamhuo-hub/HamPic@img/img/20250403122601727.png&#34; alt=&#34;image.png&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;数据集 LAION IMAGENET, 中有文字和图片的对应&lt;/p&gt;&#xA;&lt;h5 id=&#34;text--to-image&#34;&gt;Text -to-image&lt;a class=&#34;td-heading-self-link&#34; href=&#34;#text--to-image&#34; aria-label=&#34;Heading self-link&#34;&gt;&lt;/a&gt;&lt;/h5&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/hamhuo-hub/HamPic@img/img/20250403122946323.png&#34; alt=&#34;image.png&#34;&gt;&lt;/p&gt;&#xA;&lt;h4 id=&#34;stable-diffusion&#34;&gt;stable diffusion&lt;a class=&#34;td-heading-self-link&#34; href=&#34;#stable-diffusion&#34; aria-label=&#34;Heading self-link&#34;&gt;&lt;/a&gt;&lt;/h4&gt;&#xA;&lt;p&gt;三大组件&lt;/p&gt;&#xA;&lt;p&gt;TextEncoder -&amp;gt; vector&#xA;噪音 -&amp;gt; Generation Model -&amp;gt; 中间产物(图片的压缩版本)&#xA;压缩图片 -&amp;gt; decoder -&amp;gt; 图片&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/hamhuo-hub/HamPic@img/img/20250403123244144.png&#34; alt=&#34;image.png&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;分开训练后组合&lt;/p&gt;&#xA;&lt;h5 id=&#34;text-encoder&#34;&gt;Text encoder&lt;a class=&#34;td-heading-self-link&#34; href=&#34;#text-encoder&#34; aria-label=&#34;Heading self-link&#34;&gt;&lt;/a&gt;&lt;/h5&gt;&#xA;&lt;p&gt;text-encoder对图像结果影响很大 FID 越小越好, CLIP 越大越好, a为text-encoder b为predict-model大小&lt;/p&gt;</description>
    </item>
    <item>
      <title>MaximumLikelihoodEstimation</title>
      <link>http://localhost:1313/graphicsai/maximum-likelihood-estimation/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/graphicsai/maximum-likelihood-estimation/</guid>
      <description></description>
    </item>
    <item>
      <title></title>
      <link>http://localhost:1313/graphicsai/readme/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/graphicsai/readme/</guid>
      <description></description>
    </item>
    <item>
      <title></title>
      <link>http://localhost:1313/graphicsai/transformer/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/graphicsai/transformer/</guid>
      <description>&lt;h4 id=&#34;introduce&#34;&gt;Introduce&lt;a class=&#34;td-heading-self-link&#34; href=&#34;#introduce&#34; aria-label=&#34;Heading self-link&#34;&gt;&lt;/a&gt;&lt;/h4&gt;&#xA;&lt;p&gt;Input and output not same length&lt;/p&gt;&#xA;&lt;p&gt;decided by model itself which is called &lt;code&gt;Seq2Seq&lt;/code&gt; Model&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/hamhuo-hub/HamPic@img/img/20250405211059372.png&#34; alt=&#34;image.png&#34;&gt;&lt;/p&gt;&#xA;&lt;h5 id=&#34;seq2seq-model-structure&#34;&gt;Seq2Seq Model structure&lt;a class=&#34;td-heading-self-link&#34; href=&#34;#seq2seq-model-structure&#34; aria-label=&#34;Heading self-link&#34;&gt;&lt;/a&gt;&lt;/h5&gt;&#xA;&lt;p&gt;Encoder and Decoder&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;Transformer is a enhanced S2S model&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;h6 id=&#34;encoder&#34;&gt;Encoder&lt;a class=&#34;td-heading-self-link&#34; href=&#34;#encoder&#34; aria-label=&#34;Heading self-link&#34;&gt;&lt;/a&gt;&lt;/h6&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/hamhuo-hub/HamPic@img/img/20250405213147511.png&#34; alt=&#34;image.png&#34;&gt;&lt;/p&gt;&#xA;&lt;h6 id=&#34;encoder-in-transformer&#34;&gt;Encoder in Transformer&lt;a class=&#34;td-heading-self-link&#34; href=&#34;#encoder-in-transformer&#34; aria-label=&#34;Heading self-link&#34;&gt;&lt;/a&gt;&lt;/h6&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/hamhuo-hub/HamPic@img/img/20250405213243811.png&#34; alt=&#34;image.png&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;Not a layer, is multi-layer&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/hamhuo-hub/HamPic@img/img/20250405213321611.png&#34; alt=&#34;image.png&#34;&gt;&lt;/p&gt;&#xA;&lt;h4 id=&#34;decoder&#34;&gt;Decoder&lt;a class=&#34;td-heading-self-link&#34; href=&#34;#decoder&#34; aria-label=&#34;Heading self-link&#34;&gt;&lt;/a&gt;&lt;/h4&gt;&#xA;&lt;p&gt;called Autoregressive&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://cdn.jsdelivr.net/gh/hamhuo-hub/HamPic@img/img/20250405214027633.png&#34; alt=&#34;image.png&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;Introduce one of two decoder - Autoregressive decoder&lt;/p&gt;&#xA;&lt;p&gt;Decoder is generate result&lt;/p&gt;&#xA;&lt;p&gt;there has a way make seq as input&lt;/p&gt;</description>
    </item>
    <item>
      <title></title>
      <link>http://localhost:1313/graphicsai/vae/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/graphicsai/vae/</guid>
      <description></description>
    </item>
  </channel>
</rss>
