<!doctype html>
<html itemscope itemtype="http://schema.org/WebPage" lang="en" class="no-js">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">


<link rel="shortcut icon" href="/favicons/favicon.ico" >
<link rel="apple-touch-icon" href="/favicons/apple-touch-icon-180x180.png" sizes="180x180">
<link rel="icon" type="image/png" href="/favicons/favicon-16x16.png" sizes="16x16">
<link rel="icon" type="image/png" href="/favicons/favicon-32x32.png" sizes="32x32">
<link rel="icon" type="image/png" href="/favicons/android-36x36.png" sizes="36x36">
<link rel="icon" type="image/png" href="/favicons/android-48x48.png" sizes="48x48">
<link rel="icon" type="image/png" href="/favicons/android-72x72.png" sizes="72x72">
<link rel="icon" type="image/png" href="/favicons/android-96x96.png" sizes="96x96">
<link rel="icon" type="image/png" href="/favicons/android-144x144.png" sizes="144x144">
<link rel="icon" type="image/png" href="/favicons/android-192x192.png" sizes="192x192">

<title>DINOv2 | Hamhuo</title>
<meta name="description" content="基於ViT生成穩定通用視覺特徵的大規模訓練方法">
<meta property="og:url" content="https://example.docsy.dev/machinelearning/dinov2/">
  <meta property="og:site_name" content="Hamhuo">
  <meta property="og:title" content="DINOv2">
  <meta property="og:description" content="基於ViT生成穩定通用視覺特徵的大規模訓練方法">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="machinelearning">
    <meta property="article:modified_time" content="2025-05-13T16:34:01+08:00">
    <meta property="article:tag" content="ML">

  <meta itemprop="name" content="DINOv2">
  <meta itemprop="description" content="基於ViT生成穩定通用視覺特徵的大規模訓練方法">
  <meta itemprop="dateModified" content="2025-05-13T16:34:01+08:00">
  <meta itemprop="wordCount" content="857">
  <meta itemprop="keywords" content="ML">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="DINOv2">
  <meta name="twitter:description" content="基於ViT生成穩定通用視覺特徵的大規模訓練方法">
<link rel="preload" href="/scss/main.min.efa4f5cb71c380c3b004e82688c50336ed879ede78e66421e634308a89b04c3f.css" as="style" integrity="sha256-76T1y3HDgMOwBOgmiMUDNu2Hnt545mQh5jQwiomwTD8=" crossorigin="anonymous">
<link href="/scss/main.min.efa4f5cb71c380c3b004e82688c50336ed879ede78e66421e634308a89b04c3f.css" rel="stylesheet" integrity="sha256-76T1y3HDgMOwBOgmiMUDNu2Hnt545mQh5jQwiomwTD8=" crossorigin="anonymous">
<script
  src="https://code.jquery.com/jquery-3.7.1.min.js"
  integrity="sha512-v2CJ7UaYy4JwqLDIrZUI/4hqeoQieOmAZNXBeQyjo21dadnwR+8ZaIJVT8EE2iyI61OV8e6M8PP2/4hpQINQ/g=="
  crossorigin="anonymous"></script>

  </head>
  <body class="td-page">
    <header>
      <nav class="td-navbar js-navbar-scroll" data-bs-theme="dark">
<div class="container-fluid flex-column flex-md-row">
  <a class="navbar-brand" href="/"><span class="navbar-brand__logo navbar-logo"><svg id="Layer_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 500 500" style="enable-background:new 0 0 500 500"><g><path style="fill:#fff" d="M116.8525 421.9722c-5.7041.0-10.3442-4.3127-10.3442-9.6129V88.183c0-5.3002 4.6401-9.6117 10.3442-9.6117H320.858c3.0347.0 9.3959.5498 11.7506 2.6302l.3545.3442 58.905 63.2912c2.3101 2.491 2.9202 8.4928 2.9202 11.3184v256.2039c0 5.3002-4.6407 9.6129-10.3436 9.6129H116.8525z"/><g><g><g><path style="fill:#767676" d="M384.4445 423.2066H116.852c-6.3839.0-11.5786-4.8658-11.5786-10.8474V88.1831c0-5.9804 5.1947-10.8461 11.5786-10.8461h204.0062c.377.0 9.2786.0329 12.568 2.9389l.3947.3833 58.9508 63.337c3.2135 3.4652 3.2514 11.7924 3.2514 12.1593v256.2036C396.0231 418.3408 390.8284 423.2066 384.4445 423.2066zM116.5079 411.9189c.0848.0278.1999.0531.3441.0531h267.5925c.1442.0.2581-.0253.3441-.0531V156.1556c-.0076-.9033-.3593-3.7347-.7034-5.0037l-57.6527-61.9416c-1.4651-.3176-4.4533-.6389-5.5742-.6389H116.852c-.143.0-.2594.024-.3441.0531V411.9189zm267.4533-261.149zM327.0321 89.371v.0013V89.371z"/></g></g></g><g><g><path style="fill:#5b7fc0" d="M189.0874 210.1754l.0012-.0012c7.7751.0012 15.0295 4.1862 18.932 10.9234 1.9177 3.3159 2.9305 7.1011 2.9293 10.9378.0 5.8394-2.2733 11.3304-6.4032 15.4604-4.1288 4.1288-9.6186 6.4032-15.458 6.4032s-11.328-2.2733-15.458-6.4032-6.4032-9.6186-6.4056-15.4628c.0012-6.025 2.454-11.4897 6.4116-15.4473C177.5953 212.627 183.0601 210.1742 189.0874 210.1754zm7.993 21.8576c.0012-1.4042-.3687-2.7868-1.063-3.9887-1.4293-2.4684-4.0833-3.9995-6.9299-4.0019-4.4077.0024-7.993 3.5877-7.993 7.993.0 2.1356.832 4.1431 2.3427 5.6539 1.5083 1.5083 3.5159 2.3403 5.6503 2.3415 2.1356.0 4.1443-.8308 5.6539-2.3403S197.0816 234.1722 197.0804 232.033z"/><path style="opacity:.3;fill:#fff" d="M189.0898 210.176c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3136 2.9377 7.0988 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8066-21.8612-21.8613.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 212.6276 183.0612 210.176 189.0898 210.176zm7.9941 21.8612c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 236.239 197.0839 234.2399 197.0839 232.0372z"/><g><defs><path id="SVGID_1_" d="M194.7376 237.6875c-1.4461 1.4461-3.4452 2.3439-5.6479 2.3439-4.4077-.0024-7.9918-3.5865-7.9942-7.9942.0024-4.4125 3.5937-7.999 7.9942-7.9942 2.8443.0 5.497 1.5323 6.924 3.9983.6991 1.2067 1.0702 2.5881 1.0702 3.9959C197.0839 234.2399 196.1861 236.239 194.7376 237.6875z"/></defs><clipPath id="SVGID_2_"><use xlink:href="#SVGID_1_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_2_);fill:#fff" d="M190.0704 225.0237c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9546.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.663-2.8588-6.116.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C193.7885 225.7247 191.9774 225.0237 190.0704 225.0237z"/><path style="opacity:.13;clip-path:url(#SVGID_2_);fill:#020202" d="M190.0704 225.0237c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9546.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.663-2.8588-6.116.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C193.7885 225.7247 191.9774 225.0237 190.0704 225.0237z"/></g><g><defs><path id="SVGID_3_" d="M189.0898 210.176c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3136 2.9377 7.0988 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8066-21.8612-21.8613.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 212.6276 183.0612 210.176 189.0898 210.176zm7.9941 21.8612c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 236.239 197.0839 234.2399 197.0839 232.0372z"/></defs><clipPath id="SVGID_4_"><use xlink:href="#SVGID_3_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_4_);fill:#5b7fc0" d="M172.6595 215.6045c-3.96 3.96-6.4116 9.4235-6.4116 15.452-.0024 12.0547 9.8066 21.8636 21.8613 21.8612 12.0547.0024 21.8636-9.797 21.8613-21.8612.0024-3.8475-1.0151-7.6326-2.9353-10.9462-3.8977-6.7324-11.1497-10.9151-18.926-10.9151C182.0806 209.1953 176.6171 211.647 172.6595 215.6045z"/></g></g><rect x="198.8952" y="225.1043" style="fill:#5b7fc0" width="122.6266" height="13.8671"/></g><g><path style="fill:#d95140" d="M189.0874 155.7611l.0012-.0012c7.7751.0012 15.0295 4.1862 18.932 10.9234 1.9177 3.3159 2.9305 7.1011 2.9293 10.9378.0 5.8394-2.2733 11.3304-6.4032 15.4604-4.1288 4.1288-9.6186 6.4032-15.458 6.4032s-11.328-2.2733-15.458-6.4032-6.4032-9.6186-6.4056-15.4628c.0012-6.0249 2.454-11.4897 6.4116-15.4473C177.5953 158.2128 183.0601 155.7599 189.0874 155.7611zm7.993 21.8577c.0012-1.4042-.3687-2.7868-1.063-3.9887-1.4293-2.4684-4.0833-3.9995-6.9299-4.0019-4.4077.0024-7.993 3.5877-7.993 7.993.0 2.1356.832 4.1431 2.3427 5.6539 1.5083 1.5083 3.5159 2.3403 5.6503 2.3415 2.1356.0 4.1443-.8308 5.6539-2.3403C196.2508 181.7667 197.0816 179.758 197.0804 177.6188z"/><path style="opacity:.3;fill:#fff" d="M189.0898 155.7617c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3135 2.9377 7.0987 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8066-21.8612-21.8613.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 158.2134 183.0612 155.7617 189.0898 155.7617zm7.9941 21.8613c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 181.8248 197.0839 179.8256 197.0839 177.623z"/><g><defs><path id="SVGID_5_" d="M194.7376 183.2733c-1.4461 1.4461-3.4452 2.3439-5.6479 2.3439-4.4077-.0024-7.9918-3.5865-7.9942-7.9942.0024-4.4125 3.5937-7.9989 7.9942-7.9942 2.8443.0 5.497 1.5323 6.924 3.9983.6991 1.2067 1.0702 2.5881 1.0702 3.9959C197.0839 179.8256 196.1861 181.8248 194.7376 183.2733z"/></defs><clipPath id="SVGID_6_"><use xlink:href="#SVGID_5_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_6_);fill:#fff" d="M190.0704 170.6095c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9546.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.663-2.8588-6.116.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C193.7885 171.3104 191.9774 170.6095 190.0704 170.6095z"/><path style="opacity:.13;clip-path:url(#SVGID_6_);fill:#020202" d="M190.0704 170.6095c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9546.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.663-2.8588-6.116.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C193.7885 171.3104 191.9774 170.6095 190.0704 170.6095z"/></g><g><defs><path id="SVGID_7_" d="M189.0898 155.7617c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3135 2.9377 7.0987 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8066-21.8612-21.8613.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 158.2134 183.0612 155.7617 189.0898 155.7617zm7.9941 21.8613c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 181.8248 197.0839 179.8256 197.0839 177.623z"/></defs><clipPath id="SVGID_8_"><use xlink:href="#SVGID_7_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_8_);fill:#d95140" d="M172.6595 161.1903c-3.96 3.96-6.4116 9.4235-6.4116 15.452-.0024 12.0547 9.8066 21.8636 21.8613 21.8613 12.0547.0024 21.8636-9.797 21.8613-21.8613.0024-3.8474-1.0151-7.6326-2.9353-10.9462-3.8977-6.7324-11.1497-10.9151-18.926-10.9151C182.0806 154.7811 176.6171 157.2327 172.6595 161.1903z"/></g><rect x="198.8952" y="170.69" style="fill:#d95140" width="122.6266" height="13.8671"/></g><g><g><path style="fill:#56a55c" d="M189.5379 264.6147l.0012-.0012c7.7751.0012 15.0294 4.1862 18.932 10.9235 1.9177 3.3159 2.9305 7.1011 2.9293 10.9378.0 5.8394-2.2733 11.3304-6.4032 15.4604-4.1288 4.1288-9.6186 6.4032-15.458 6.4032-5.8394.0-11.3281-2.2733-15.458-6.4032-4.13-4.13-6.4032-9.6186-6.4056-15.4628.0012-6.0249 2.454-11.4897 6.4116-15.4472C178.0458 267.0663 183.5105 264.6135 189.5379 264.6147zm7.993 21.8576c.0012-1.4042-.3687-2.7868-1.063-3.9887-1.4293-2.4684-4.0833-3.9995-6.9299-4.0019-4.4077.0024-7.993 3.5877-7.993 7.993.0 2.1356.832 4.1431 2.3427 5.6538 1.5083 1.5083 3.5159 2.3403 5.6503 2.3415 2.1356.0 4.1443-.8308 5.6539-2.3403C196.7013 290.6202 197.5321 288.6115 197.5309 286.4723z"/><path style="opacity:.3;fill:#fff" d="M189.5403 264.6153c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3135 2.9377 7.0987 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8065-21.8612-21.8613.0-6.0285 2.4516-11.492 6.4116-15.452C178.0482 267.0669 183.5117 264.6153 189.5403 264.6153zm7.9941 21.8612c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9941.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.6366 290.6783 197.5344 288.6792 197.5344 286.4765z"/><g><defs><path id="SVGID_9_" d="M195.1881 292.1268c-1.4461 1.4461-3.4452 2.3439-5.6479 2.3439-4.4077-.0024-7.9918-3.5865-7.9942-7.9942.0024-4.4125 3.5937-7.9989 7.9942-7.9941 2.8443.0 5.497 1.5323 6.924 3.9983.6991 1.2067 1.0702 2.5881 1.0702 3.9959C197.5344 288.6792 196.6366 290.6783 195.1881 292.1268z"/></defs><clipPath id="SVGID_10_"><use xlink:href="#SVGID_9_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_10_);fill:#fff" d="M190.5209 279.463c-4.4005-.0048-7.9918 3.5817-7.9942 7.9941.0011 1.9547.7088 3.7452 1.8782 5.1354-1.7446-1.4674-2.8575-3.6631-2.8588-6.1161.0024-4.4125 3.5936-7.999 7.9942-7.9941 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C194.239 280.164 192.4279 279.463 190.5209 279.463z"/><path style="opacity:.13;clip-path:url(#SVGID_10_);fill:#020202" d="M190.5209 279.463c-4.4005-.0048-7.9918 3.5817-7.9942 7.9941.0011 1.9547.7088 3.7452 1.8782 5.1354-1.7446-1.4674-2.8575-3.6631-2.8588-6.1161.0024-4.4125 3.5936-7.999 7.9942-7.9941 2.3802-1e-4 4.616 1.0833 6.1218 2.8788C194.239 280.164 192.4279 279.463 190.5209 279.463z"/></g><g><defs><path id="SVGID_11_" d="M189.5403 264.6153c7.7763.0 15.0283 4.1826 18.926 10.9151 1.9201 3.3135 2.9377 7.0987 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8613-12.0547.0024-21.8636-9.8065-21.8612-21.8613.0-6.0285 2.4516-11.492 6.4116-15.452C178.0482 267.0669 183.5117 264.6153 189.5403 264.6153zm7.9941 21.8612c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9941.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.6366 290.6783 197.5344 288.6792 197.5344 286.4765z"/></defs><clipPath id="SVGID_12_"><use xlink:href="#SVGID_11_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_12_);fill:#56a55c" d="M173.11 270.0439c-3.96 3.96-6.4116 9.4235-6.4116 15.452-.0024 12.0547 9.8066 21.8636 21.8613 21.8613 12.0547.0024 21.8636-9.797 21.8613-21.8613.0024-3.8474-1.0151-7.6326-2.9353-10.9462-3.8977-6.7325-11.1497-10.9151-18.926-10.9151C182.5311 263.6346 177.0676 266.0863 173.11 270.0439z"/></g></g><rect x="199.3456" y="279.5436" style="fill:#56a55c" width="122.6266" height="13.8671"/></g><g><g><path style="fill:#f1bc42" d="M189.0874 318.7208l.0012-.0012c7.7751.0012 15.0295 4.1862 18.932 10.9234 1.9177 3.3159 2.9305 7.1011 2.9293 10.9378.0 5.8394-2.2733 11.3305-6.4032 15.4604-4.1288 4.1288-9.6186 6.4032-15.458 6.4032s-11.328-2.2733-15.458-6.4032-6.4032-9.6186-6.4056-15.4628c.0012-6.025 2.454-11.4897 6.4116-15.4472C177.5953 321.1724 183.0601 318.7196 189.0874 318.7208zm7.993 21.8576c.0012-1.4042-.3687-2.7868-1.063-3.9887-1.4293-2.4684-4.0833-3.9995-6.9299-4.0019-4.4077.0024-7.993 3.5877-7.993 7.993.0 2.1356.832 4.1431 2.3427 5.6539 1.5083 1.5083 3.5159 2.3403 5.6503 2.3415 2.1356.0 4.1443-.8308 5.6539-2.3403S197.0816 342.7176 197.0804 340.5784z"/><path style="opacity:.3;fill:#fff" d="M189.0898 318.7214c7.7763.0 15.0283 4.1826 18.926 10.915 1.9201 3.3136 2.9377 7.0988 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8612-12.0547.0024-21.8636-9.8065-21.8612-21.8612.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 321.173 183.0612 318.7214 189.0898 318.7214zm7.9941 21.8612c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 344.7844 197.0839 342.7853 197.0839 340.5826z"/><g><defs><path id="SVGID_13_" d="M194.7376 346.2329c-1.4461 1.4461-3.4452 2.3439-5.6479 2.3439-4.4077-.0024-7.9918-3.5865-7.9942-7.9942.0024-4.4125 3.5937-7.999 7.9942-7.9942 2.8443.0 5.497 1.5323 6.924 3.9983.6991 1.2067 1.0702 2.5881 1.0702 3.9959C197.0839 342.7853 196.1861 344.7844 194.7376 346.2329z"/></defs><clipPath id="SVGID_14_"><use xlink:href="#SVGID_13_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_14_);fill:#fff" d="M190.0704 333.5691c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9547.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.6631-2.8588-6.1161.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0834 6.1218 2.8788C193.7885 334.2701 191.9774 333.5691 190.0704 333.5691z"/><path style="opacity:.13;clip-path:url(#SVGID_14_);fill:#020202" d="M190.0704 333.5691c-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0011 1.9547.7088 3.7452 1.8782 5.1354-1.7447-1.4674-2.8575-3.6631-2.8588-6.1161.0024-4.4125 3.5936-7.999 7.9942-7.9942 2.3802-1e-4 4.616 1.0834 6.1218 2.8788C193.7885 334.2701 191.9774 333.5691 190.0704 333.5691z"/></g><g><defs><path id="SVGID_15_" d="M189.0898 318.7214c7.7763.0 15.0283 4.1826 18.926 10.915 1.9201 3.3136 2.9377 7.0988 2.9353 10.9462.0024 12.0643-9.8065 21.8636-21.8613 21.8612-12.0547.0024-21.8636-9.8065-21.8612-21.8612.0-6.0285 2.4516-11.4921 6.4116-15.452C177.5977 321.173 183.0612 318.7214 189.0898 318.7214zm7.9941 21.8612c0-1.4078-.3711-2.7892-1.0702-3.9959-1.4269-2.466-4.0797-3.9983-6.924-3.9983-4.4005-.0048-7.9918 3.5817-7.9942 7.9942.0024 4.4077 3.5865 7.9918 7.9942 7.9942 2.2027.0 4.2018-.8978 5.6479-2.3439C196.1861 344.7844 197.0839 342.7853 197.0839 340.5826z"/></defs><clipPath id="SVGID_16_"><use xlink:href="#SVGID_15_" style="overflow:visible"/></clipPath><path style="clip-path:url(#SVGID_16_);fill:#f1bc42" d="M172.6595 324.15c-3.96 3.96-6.4116 9.4235-6.4116 15.452-.0024 12.0547 9.8066 21.8636 21.8613 21.8612 12.0547.0024 21.8636-9.797 21.8613-21.8612.0024-3.8474-1.0151-7.6327-2.9353-10.9462-3.8977-6.7324-11.1497-10.9151-18.926-10.9151C182.0806 317.7407 176.6171 320.1924 172.6595 324.15z"/></g></g><rect x="198.8952" y="333.6497" style="fill:#f1bc42" width="122.6266" height="13.8671"/></g></g></svg></span><span class="navbar-brand__name">Hamhuo</span></a>
  <div class="td-navbar-nav-scroll ms-md-auto" id="main_navbar">
    <ul class="navbar-nav">
      <li class="nav-item">
        <a class="nav-link" href="/codewar/"><span>Code War</span></a>
      </li>
      <li class="nav-item">
        <a class="nav-link" href="/school/"><span>Courses</span></a>
      </li>
      <li class="nav-item">
        <a class="nav-link active" href="/machinelearning/"><span>MachineLearning</span></a>
      </li>
      <li class="nav-item">
        <a class="nav-link" href="/noteself/"><span>Noteself</span></a>
      </li>
      </ul>
  </div>
  <div class="d-none d-lg-block">
    <div class="td-search">
  <div class="td-search__icon"></div>
  <input type="search" class="td-search__input form-control td-search-input" placeholder="Search this site…" aria-label="Search this site…" autocomplete="off">
</div>
  </div>
</div>
</nav>
    </header>
    <div class="container-fluid td-outer">
      <div class="td-main">
        <div class="row flex-xl-nowrap">
          <aside class="col-12 col-md-3 col-xl-2 td-sidebar d-print-none">
            <div id="td-sidebar-menu" class="td-sidebar__inner">
  <form class="td-sidebar__search d-flex align-items-center">
    <div class="td-search">
  <div class="td-search__icon"></div>
  <input type="search" class="td-search__input form-control td-search-input" placeholder="Search this site…" aria-label="Search this site…" autocomplete="off">
</div>
    <button class="btn btn-link td-sidebar__toggle d-md-none p-0 ms-3 fas fa-bars" type="button" data-bs-toggle="collapse" data-bs-target="#td-section-nav" aria-controls="td-section-nav" aria-expanded="false" aria-label="Toggle section navigation">
    </button>
  </form>
  <nav class="td-sidebar-nav collapse foldable-nav" id="td-section-nav">
    <ul class="td-sidebar-nav__section pe-md-3 ul-0">
      <li class="td-sidebar-nav__section-title td-sidebar-nav__section with-child active-path" id="m-machinelearning-li">
  <a href="/machinelearning/" class="align-left ps-0 td-sidebar-link td-sidebar-link__section tree-root" id="m-machinelearning"><span class="">MachineLearning</span></a>
  <ul class="ul-1">
    <li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child active-path" id="m-machinelearningdinov2-li">
  <input type="checkbox" id="m-machinelearningdinov2-check" checked/>
  <label for="m-machinelearningdinov2-check"><a href="/machinelearning/dinov2/" class="align-left ps-0  active td-sidebar-link td-sidebar-link__page" id="m-machinelearningdinov2"><span class="td-sidebar-nav-active-item">DINOv2</span></a></label>
  
</li>
  </ul>
</li>
    </ul>
  </nav>
</div>

          </aside>
          <aside class="d-none d-xl-block col-xl-2 td-sidebar-toc d-print-none">
            <div class="td-page-meta ms-2 pb-1 pt-2 mb-0">
<a href="https://github.com/google/docsy-example/tree/main/C:%5cUsers%5cHuoZihang%5cDocuments%5cGitHub%5cseaku-src%5ccontent%5cen%5cmachinelearning%5cdinov2.md" class="td-page-meta--view td-page-meta__view" target="_blank" rel="noopener"><i class="fa-solid fa-file-lines fa-fw"></i> View page source</a>
  <a href="https://github.com/google/docsy-example/edit/main/C:%5cUsers%5cHuoZihang%5cDocuments%5cGitHub%5cseaku-src%5ccontent%5cen%5cmachinelearning%5cdinov2.md" class="td-page-meta--edit td-page-meta__edit" target="_blank" rel="noopener"><i class="fa-solid fa-pen-to-square fa-fw"></i> Edit this page</a>
  <a href="https://github.com/google/docsy-example/new/main/C:/Users/HuoZihang/Documents/GitHub/seaku-src/content/en/machinelearning?filename=change-me.md&amp;value=---%0Atitle%3A&#43;%22Long&#43;Page&#43;Title%22%0AlinkTitle%3A&#43;%22Short&#43;Nav&#43;Title%22%0Aweight%3A&#43;100%0Adescription%3A&#43;%3E-%0A&#43;&#43;&#43;&#43;&#43;Page&#43;description&#43;for&#43;heading&#43;and&#43;indexes.%0A---%0A%0A%23%23&#43;Heading%0A%0AEdit&#43;this&#43;template&#43;to&#43;create&#43;your&#43;new&#43;page.%0A%0A%2A&#43;Give&#43;it&#43;a&#43;good&#43;name%2C&#43;ending&#43;in&#43;%60.md%60&#43;-&#43;e.g.&#43;%60getting-started.md%60%0A%2A&#43;Edit&#43;the&#43;%22front&#43;matter%22&#43;section&#43;at&#43;the&#43;top&#43;of&#43;the&#43;page&#43;%28weight&#43;controls&#43;how&#43;its&#43;ordered&#43;amongst&#43;other&#43;pages&#43;in&#43;the&#43;same&#43;directory%3B&#43;lowest&#43;number&#43;first%29.%0A%2A&#43;Add&#43;a&#43;good&#43;commit&#43;message&#43;at&#43;the&#43;bottom&#43;of&#43;the&#43;page&#43;%28%3C80&#43;characters%3B&#43;use&#43;the&#43;extended&#43;description&#43;field&#43;for&#43;more&#43;detail%29.%0A%2A&#43;Create&#43;a&#43;new&#43;branch&#43;so&#43;you&#43;can&#43;preview&#43;your&#43;new&#43;file&#43;and&#43;request&#43;a&#43;review&#43;via&#43;Pull&#43;Request.%0A" class="td-page-meta--child td-page-meta__child" target="_blank" rel="noopener"><i class="fa-solid fa-pen-to-square fa-fw"></i> Create child page</a>
  <a href="https://github.com/google/docsy-example/issues/new?title=DINOv2" class="td-page-meta--issue td-page-meta__issue" target="_blank" rel="noopener"><i class="fa-solid fa-list-check fa-fw"></i> Create documentation issue</a>
  <a href="https://github.com/google/docsy/issues/new" class="td-page-meta--project td-page-meta__project-issue" target="_blank" rel="noopener"><i class="fa-solid fa-list-check fa-fw"></i> Create project issue</a>
  <a id="print" href="/machinelearning/_print/"><i class="fa-solid fa-print fa-fw"></i> Print entire section</a>

</div>

            <div class="td-toc">
        <nav id="TableOfContents">
  <ul>
    <li>
      <ul>
        <li></li>
      </ul>
    </li>
  </ul>
</nav>
      </div>
    
            <div class="taxonomy taxonomy-terms-cloud taxo-tags">
      <h5 class="taxonomy-title">Tag Cloud</h5>
      <ul class="taxonomy-terms">
        <li><a class="taxonomy-term" href="https://example.docsy.dev/tags/gaming/" data-taxonomy-term="gaming"><span class="taxonomy-label">Gaming</span><span class="taxonomy-count">4</span></a></li>
        <li><a class="taxonomy-term" href="https://example.docsy.dev/tags/ml/" data-taxonomy-term="ml"><span class="taxonomy-label">ML</span><span class="taxonomy-count">1</span></a></li>
        <li><a class="taxonomy-term" href="https://example.docsy.dev/tags/oj/" data-taxonomy-term="oj"><span class="taxonomy-label">OJ</span><span class="taxonomy-count">9</span></a></li>
        <li><a class="taxonomy-term" href="https://example.docsy.dev/tags/sad/" data-taxonomy-term="sad"><span class="taxonomy-label">SAD</span><span class="taxonomy-count">3</span></a></li>
        <li><a class="taxonomy-term" href="https://example.docsy.dev/tags/%E6%97%A5%E5%BF%97/" data-taxonomy-term="%E6%97%A5%E5%BF%97"><span class="taxonomy-label">日志</span><span class="taxonomy-count">3</span></a></li>
        </ul>
    </div>
  <div class="taxonomy taxonomy-terms-cloud taxo-categories">
      <h5 class="taxonomy-title">Categories</h5>
      <ul class="taxonomy-terms">
        <li><a class="taxonomy-term" href="https://example.docsy.dev/categories/codewar/" data-taxonomy-term="codewar"><span class="taxonomy-label">CodeWar</span><span class="taxonomy-count">9</span></a></li>
        <li><a class="taxonomy-term" href="https://example.docsy.dev/categories/ml/" data-taxonomy-term="ml"><span class="taxonomy-label">ML</span><span class="taxonomy-count">1</span></a></li>
        <li><a class="taxonomy-term" href="https://example.docsy.dev/categories/school/" data-taxonomy-term="school"><span class="taxonomy-label">School</span><span class="taxonomy-count">10</span></a></li>
        <li><a class="taxonomy-term" href="https://example.docsy.dev/categories/%E6%97%A5%E5%BF%97/" data-taxonomy-term="%E6%97%A5%E5%BF%97"><span class="taxonomy-label">日志</span><span class="taxonomy-count">3</span></a></li>
        </ul>
    </div>
  
	
          </aside>
          <main class="col-12 col-md-9 col-xl-8 ps-md-5" role="main">
            
  

            <nav aria-label="breadcrumb" class="td-breadcrumbs">
  <ol class="breadcrumb">
  <li class="breadcrumb-item">
    <a href="/machinelearning/">MachineLearning</a></li>
  <li class="breadcrumb-item active" aria-current="page">
    DINOv2</li>
  </ol>
</nav>
<div class="td-content">
	<h1>DINOv2</h1>
	<div class="lead">基於ViT生成穩定通用視覺特徵的大規模訓練方法</div>
	<header class="article-meta">
		<div class="taxonomy taxonomy-terms-article taxo-tags">
  <h5 class="taxonomy-title">Tags:</h5>
  <ul class="taxonomy-terms">
    <li><a class="taxonomy-term" href="https://example.docsy.dev/tags/ml/" data-taxonomy-term="ml"><span class="taxonomy-label">ML</span></a></li>
    </ul>
</div>
<div class="taxonomy taxonomy-terms-article taxo-categories">
  <h5 class="taxonomy-title">Categories:</h5>
  <ul class="taxonomy-terms">
    <li><a class="taxonomy-term" href="https://example.docsy.dev/categories/ml/" data-taxonomy-term="ml"><span class="taxonomy-label">ML</span></a></li>
    </ul>
</div>

  </header>
	<p>目錄</p>
<ol>
<li>ViT</li>
<li>DINO</li>
<li>DINOv2
3.1 論文與原理
3.2 代碼簡單分析</li>
<li>sd-DINO
4.1 論文與原理
4.2. 代碼簡單分析</li>
<li>總結</li>
</ol>
<h4 id="vit">ViT</h4>
<p>*<code>Transformer</code> 在圖像上的拓展
<a href="https://arxiv.org/abs/2010.11929">An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale</a></p>
<blockquote>
<p>===A neural network architecture that&rsquo;s revolutionized natural language processing (NLP) and is now being used in various other fields like computer vision and audio generation==.
&ndash;<em>wikipedia</em></p></blockquote>
<p><img src="https://raw.githubusercontent.com/hamhuo-hub/HamPic/img/20250507002140282.png" alt="Pasted image 20250505163912"></p>
<blockquote>
<p><em>經典的Transformer</em></p></blockquote>
<p>Transformer分爲兩部分，左側編碼層用於將數據（Token）投影到向量空間，其中相似的數據會投影到相似的向量。右側用於生成任務（GPT預測下一個詞）我們主要關注左側的編碼部分</p>
<p><img src="https://raw.githubusercontent.com/hamhuo-hub/HamPic/img/20250507002140283.png" alt="image.png"></p>
<blockquote>
<p><em>經典Transformer中的示例，語義特徵相似的圖片方向相似（不是ViT）</em></p></blockquote>
<p><img src="https://raw.githubusercontent.com/hamhuo-hub/HamPic/img/20250507002140284.png" alt="Pasted image 20250505165805"></p>
<blockquote>
<p><em>嵌入可視化 左側是不同的交通標誌（如 STOP、ALTO、禁止進入、右轉等），每個圖像被編碼成一組特徵向量，- STOP 與 ALTO（西語“停止”）以及禁止進入標誌聚集在一起，右轉標誌則落在另一個明顯不同的區域。</em></p></blockquote>
<p>Vision Transformer 是 Transformer 對圖像數據的拓展。相較與 <code>CNN</code>，<code>ViT</code> 是基於自注意力的架構 （Self-attention-based architectures）。</p>
<blockquote>
<p>Vision Transformer（ViT）結構上與自然語言處理中的 Transformer 類似，其核心是將圖像切分為固定大小的 patch，嵌入為向量後加入位置編碼，經過多層 Transformer 模塊進行特徵建模。ViT 將圖像轉換為高維特徵空間中的一組表示，使得這些特徵在該空間中具有結構化或可分性，便於後續分類等下游任務。這些高維特徵不直接對應語義單元，而是作為模型輸出語義預測的中間表徵。</p></blockquote>
<p>NLP中的Token是通過拆分句子爲詞組得到的，在圖像中這是由圖像補丁(Patch)得到的</p>
<p><img src="https://raw.githubusercontent.com/hamhuo-hub/HamPic/img/20250507002140285.png" alt="Pasted image 20250505171606"></p>
<blockquote>
<p><em>一張圖片</em></p></blockquote>
<p>輸入的圖像是由三個顏色通道RGB，以及寬和高組成。將一張圖片拆成大小相同的小塊就可以作爲Token輸入到編碼器中。編碼器會對每個patch生成嵌入（Embedding）由於拆分圖像時會失去位置信息，所以在施加注意力前（Attention）需要加上位置向量</p>
<blockquote>
<p>在 Vision Transformer (ViT) 中，位置編碼採用可學習的位置嵌入（learnable positional embeddings），為每個圖像 patch 和 CLS Token 分配一個獨特的向量，表示其在圖像中的空間位置。ViT 的可學習嵌入能通過訓練適應圖像的 2D 空間結構，提供靈活的位置信息。這些嵌入與 patch 特徵一起輸入 Transformer，幫助注意力機制捕捉 patch 之間的空間關係。CLS Token 作為一個特殊的標記，利用位置嵌入的上下文，通過多層注意力機制聚合所有 patch 的特徵，生成用於下游任務（如分類）的全局表示</p></blockquote>
<p><img src="https://raw.githubusercontent.com/hamhuo-hub/HamPic/img/20250507002140286.png" alt="Pasted image 20250505172028"></p>
<blockquote>
<p>ViT 架構</p></blockquote>
<p>Embedding 經過多個Transformer layer層後（基本上是許多注意力層，前向層交替）後經過歸一化得到高維特徵。</p>
<blockquote>
<p>許多細節此處忽略，，比如學習不同patch之間輸入距離的函數，殘差和跳躍鏈接。這些內容和主題相差甚遠此處忽略
<a href="https://www.youtube.com/watch?v=j3VNqtJUoz0&amp;t=3s">ViT Video on Youtube</a></p></blockquote>
<p>在加上分類頭後（MLP頭爲例）可以輸出類別</p>
<p><img src="https://raw.githubusercontent.com/hamhuo-hub/HamPic/img/20250507002140287.png" alt="Pasted image 20250506161954"></p>
<h4 id="dino">DINO</h4>
<p><em>一種新的基於 ViT自監督訓練方法</em>
<a href="https://arxiv.org/abs/2104.14294">Emerging Properties in Self-Supervised Vision Transformers</a></p>
<p>DINO模型實際上只是對ViT的一個包裝，實現了自蒸餾（知識蒸餾的一種）</p>
<h5 id="知識蒸餾knowladge-distillation">知識蒸餾（Knowladge distillation）</h5>
<p>先說知識蒸餾，知識蒸餾的目的是爲了壓縮模型，節省計算資源。也就是訓練一個小型模型來模擬大型模型的輸出，兩個模型從架構到參數都有細微區別。</p>
<p><img src="https://raw.githubusercontent.com/hamhuo-hub/HamPic/img/20250507002140288.png" alt="Pasted image 20250505200956"></p>
<blockquote>
<p>簡單的教師學生蒸餾模型</p></blockquote>
<blockquote>
<p>Self-training aims at improving the quality of features by propagating a small initial set of annotations to a large set of unlabeled instances. This ==propagation== can either be done with hard assignments of labels or with a soft assignment . When using ==soft labels==, the approach is often referred to as ==knowledge distillation==
&ndash; 2104.14294</p></blockquote>
<p>知識蒸餾流程
我們已經擁有訓練好的大模型（teacher）以及標籤數據集
我們讓student同時訓練標籤（硬標籤）以及教師在無標籤數據集上的概率分佈（僞標籤/軟標籤）我們的目的是$$
訓練一個學生網絡 gθs​​ 去模仿一個教師網絡 gθt​​ 的輸出。
$$
其中s是學生參數，t是教師參數
對於輸入的圖像x，pt和ps分別是教師和學生網絡在高維空間的概率分佈（softmax）<img src="https://raw.githubusercontent.com/hamhuo-hub/HamPic/img/20250507002140289.png" alt="Pasted image 20250505204354">
其中T是softmax的溫度，控制平滑程度的
對於已經給定的教師t，使用 <strong>損失函數</strong>（交叉熵），最小化交叉熵來訓練學生網絡的參數s，儘量是學生的輸出分佈和教師一致<img src="https://raw.githubusercontent.com/hamhuo-hub/HamPic/img/20250507002140290.png" alt="Pasted image 20250505204830"><img src="https://raw.githubusercontent.com/hamhuo-hub/HamPic/img/20250507002140291.png" alt="Pasted image 20250505204913"></p>
<p>但我們希望無需任何標籤實現自監督學習，這就是DINO的目的</p>
<blockquote>
<p>DINO 英文來自於 Self-==DI==stillation with ==NO== lable</p></blockquote>
<p>DINO的核心思想如下</p>
<ul>
<li>
<p>給一張圖片進行兩種不同的數據增強（<code>augment</code>）稱全局裁剪和局部裁剪
<em>从给定图像生成一个由不同视图组成的集合 V。该集合包含两个全局视图 (globe crop)x1g 和 x2g 以及几个分辨率较低的局部视图(local crop)（一般8個）。所有裁剪图像都经过学生模型，而只有全局视图经过老师模型</em><img src="https://raw.githubusercontent.com/hamhuo-hub/HamPic/img/20250507002140292.png" alt="Pasted image 20250505195446"></p>
<p><img src="https://raw.githubusercontent.com/hamhuo-hub/HamPic/img/20250507002140293.png" alt="Pasted image 20250505210216"></p>
</li>
<li>
<p>用<strong>student</strong>網絡來學習，並用<strong>teacher</strong>網絡產生教學信號
<em>不需要標籤，學習的目的是讓 student 的輸出在不同增強下與 teacher 對齊</em>
<em>和知識蒸餾不同的是，這裏教師隨學生一起訓練, 在訓練時動態構建， teacher可以看做是學生的一個副本。</em>
輸入的局部和全局裁剪經過兩個網絡以及softmax後輸出概率分佈（共65532個類）比較教師和學生的輸出，其中教師在輸出softmax概率前會做中心化，教師的輸出叫教學信號。這裏的輸出可以類比latent space，圖像特徵潛空間
<img src="https://raw.githubusercontent.com/hamhuo-hub/HamPic/img/20250507002140294.png" alt="Pasted image 20250505195513">
由於輸入是局部和全局的裁剪，我們訓練目標是找到==局部到全局==的對應或者說讓模型知道那些的圖片一樣那些不一樣（<em>判別式方法：通常指直接建模條件概率 𝑃 ( 𝑦 ∣ 𝑥 ) ，即給定輸入 𝑥 x，預測輸出 𝑦 的概率。這裏是給定圖像 𝑥 ，預測其增強版本的特徵或偽標籤分佈。</em>）
我們鼓勵局部到全局的對應。和知識蒸餾類似我們使用修改過的交叉熵損失函數求最小值（隨機梯度下降）从给定图像生成一个由不同视图组成的集合 V。该集合包含两个全局视图和局部試圖 <img src="https://raw.githubusercontent.com/hamhuo-hub/HamPic/img/20250507002140295.png" alt="Pasted image 20250505210352">
其實，對於教師網絡和學生網絡同時做梯度下降求最小值沒有任何意義。我們的目標是讓學生模仿教師，而不是互相調整所以這裏使用參數sg阻止梯度更新轉而使用 EMA 指數平均線/動量平均值（股票的K線）來更新網絡。根據學生的過去迭代來動態構建教師網絡
在每個梯度更新中，只有學生 student 是唯一需要學習的網絡，教師只是學生的指數移動平均線（副本）
<img src="https://raw.githubusercontent.com/hamhuo-hub/HamPic/img/20250507002140296.png" alt="Pasted image 20250506075202">
指數移動平均（Exponential Moving Average, EMA）公式，目的是用來更新教師網絡（teacher network） 的參數 θt​，讓它平滑地追蹤學生網絡（student network）的參數 θs，其 中lamda是溫度，用於控制學生參數佔比也就是教師更新參數的平滑程度，默認0.992
因此經過 EMA, ​中心化，阻止教師的梯度加上學生的參數後教師可以認爲是==學生的一個更穩定的版本==（正則化）這樣，教師網絡就能領先與學生網絡並產生教學信號引導學生訓練。<img src="https://raw.githubusercontent.com/hamhuo-hub/HamPic/img/20250507002140297.png" alt="Pasted image 20250506163246"></p>
</li>
</ul>
<p>核心算法（僞代碼）</p>
<div class="highlight"><pre tabindex="0" style="color:#2f1e2e;background-color:#e7e9db;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>gt<span style="color:#5bc4bf">.</span>params <span style="color:#5bc4bf">=</span> gs<span style="color:#5bc4bf">.</span>params  <span style="color:#8d8687"># 初始化 teacher 為 student 的拷貝，兩者是一模一樣的</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#815ba4">for</span> x <span style="color:#5bc4bf">in</span> loader:  <span style="color:#8d8687"># 對於每個 batch</span>
</span></span><span style="display:flex;"><span>    x1, x2 <span style="color:#5bc4bf">=</span> augment(x), augment(x)  <span style="color:#8d8687"># 同一張圖的兩個不同增強版本</span>
</span></span><span style="display:flex;"><span>    s1, s2 <span style="color:#5bc4bf">=</span> gs(x1), gs(x2)          <span style="color:#8d8687"># student 對增強圖像的輸出 (n x K)</span>
</span></span><span style="display:flex;"><span>    t1, t2 <span style="color:#5bc4bf">=</span> gt(x1), gt(x2)          <span style="color:#8d8687"># teacher 的輸出 (n x K)</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#8d8687"># 計算對稱損失，讓 s1 對齊 t2，s2 對齊 t1</span>
</span></span><span style="display:flex;"><span>    loss <span style="color:#5bc4bf">=</span> H(t1, s2)<span style="color:#5bc4bf">/</span><span style="color:#f99b15">2</span> <span style="color:#5bc4bf">+</span> H(t2, s1)<span style="color:#5bc4bf">/</span><span style="color:#f99b15">2</span>
</span></span><span style="display:flex;"><span>    loss<span style="color:#5bc4bf">.</span>backward()  <span style="color:#8d8687"># 反向傳播</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    update(gs)  <span style="color:#8d8687"># 使用 SGD 更新 student 參數</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#8d8687"># Momentum 更新 teacher 參數（無反向傳播）</span>
</span></span><span style="display:flex;"><span>    gt<span style="color:#5bc4bf">.</span>params <span style="color:#5bc4bf">=</span> l<span style="color:#5bc4bf">*</span>gt<span style="color:#5bc4bf">.</span>params <span style="color:#5bc4bf">+</span> (<span style="color:#f99b15">1</span><span style="color:#5bc4bf">-</span>l)<span style="color:#5bc4bf">*</span>gs<span style="color:#5bc4bf">.</span>params <span style="color:#8d8687">#學生佔比很低 0.008</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#8d8687"># 更新中心向量（用於 teacher 輸出的穩定化與對齊）</span>
</span></span><span style="display:flex;"><span>    C <span style="color:#5bc4bf">=</span> m<span style="color:#5bc4bf">*</span>C <span style="color:#5bc4bf">+</span> (<span style="color:#f99b15">1</span><span style="color:#5bc4bf">-</span>m)<span style="color:#5bc4bf">*</span>cat([t1, t2])<span style="color:#5bc4bf">.</span>mean(dim<span style="color:#5bc4bf">=</span><span style="color:#f99b15">0</span>)
</span></span></code></pre></div><p>總而言之，DINO本質上是對ViT進行的封裝，核心架構依舊是ViT但利用共蒸餾改進了訓練方法。DINO關注的是如何訓練ViT，本質是一種訓練方法</p>
<h4 id="dinov2">DINOv2</h4>
<p><em>基於ViT的大規模預訓練圖像特徵生成基礎模型</em>
<a href="https://arxiv.org/abs/2304.07193">Learning Robust Visual Features without Supervision</a></p>
<blockquote>
<p>自然语言处理领域近期在海量数据模型预训练方面取得的突破，为计算机视觉领域类似的基础模型开辟了道路。这些模型可以生成通用的视觉特征（即无需微调即可跨图像分布和任务发挥作用的特征），从而大大简化图像在任何系统中的使用。</p></blockquote>
<p>NLP在擴大訓練規模後可以得到高質量穩定的特徵，DINOv2希望通過類似的思路可以的到高==質量的圖像特徵==。
DINOv2 在DINO的基礎上擴大了訓練規模，其大多数技术贡献旨在加速和稳定大规模训练。</p>
<p><img src="https://raw.githubusercontent.com/hamhuo-hub/HamPic/img/20250507002140298.png" alt="Pasted image 20250506163036"></p>
<blockquote>
<p><em>擴大訓練規模的效果</em></p></blockquote>
<p>DINOv2爲了擴大與穩定訓練規模做了以下改進</p>
<ul>
<li>
<p>精選數據集（automatic pipeline）
對於生成通用視覺特徵的目標，自監督學習在小型精選數據集上取得了進展，但當使用大量非精選的數據訓練時出現了特徵質量下降。这是因为缺乏对数据质量和多样性的控制，而这两者对于生成良好的特征至关重要。
爲此數據處理會自動精選圖像。来自精选和非精选数据源的图像首先被映射到嵌入向量。然后，非精选图像会进行去重，再与精选图像进行匹配。最终的组合通过自监督检索系统扩充了初始数据集。<img src="https://raw.githubusercontent.com/hamhuo-hub/HamPic/img/20250507002140299.png" alt="Pasted image 20250506170602"></p>
<p>數據庫：首先，我们从公开的爬取网页数据存储库中收集了原始的、未经过滤的图片数据集。進行去重（PCA哈希去重、NSFW 过滤以及可识别人脸模糊处理）。收集到的所有圖像會作爲未精選數據集。和精選的數據集（Imagenet，google）一同進入embedding編碼環節</p>
<p>編碼：使用在 ImageNet-22k 上预训练的自监督 ViT-H/16 网络计算图像嵌入，并使用==余弦相 似度==作为图像之间的距离度量。計算相似度是爲了刪除相似圖片。（Deduplication）
由於我們並不清楚蒐集來的數據內容是什麼，如果含大量貓的圖片那麼模型可能只會得到貓的 特徵（<em>數據偏奇/泛化不足</em>）</p>
<p>使用聚類可以有效解決，我们对未整理的数据执行 ==K 均值聚类==，分爲若干個語義相近的群。<img src="https://raw.githubusercontent.com/hamhuo-hub/HamPic/img/20250507002140300.png" alt="Pasted image 20250506171035">
假設你有一批查詢圖片（想找與它們類似的圖片），對於每張查詢圖片，去整個資料庫中找「最接近的 N 張圖」，N 通常設為 4。
如果 N 設太大，檢索的圖片會出現「同一張圖片被多個查詢圖片檢索到」，造成重複，這種情況稱為==<strong>碰撞</strong>（collision）==。檢索後的圖片會合查詢圖片一起組合爲精選數據集<img src="https://raw.githubusercontent.com/hamhuo-hub/HamPic/img/20250507002140301.png" alt="Pasted image 20250506170717"></p>
</li>
<li>
<p>組合DINO 损失和 iBOT 损失（iBOT負責遮罩，patch級別的圖像特徵損失。 DINO負責整體圖像的特徵損失）</p>
</li>
<li>
<p>并以 SwAV 做中心化（Centering）。添加了一个正则化项来扩展特征（KoLeo 損失：正則化 CLS 標記，增強表示多樣性）</p>
</li>
</ul>
<p>==最後兩項很複雜，我看不懂。這裏跳過==</p>
<h5 id="代碼部分dinov2dino">代碼部分（DINOv2/DINO）</h5>
<blockquote>
<p>DINO的倉庫更新到DINOv2了，所以在這裏一起講
<img src="https://raw.githubusercontent.com/hamhuo-hub/HamPic/img/20250507002140302.png" alt="Pasted image 20250506202955">
<em>原始的 DINO倉庫，第一行建議重定向到 DINOv2</em></p></blockquote>
<p>以下是位於 <code>train.py</code> 的訓練主循環（精簡版）</p>
<div class="highlight"><pre tabindex="0" style="color:#2f1e2e;background-color:#e7e9db;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#8d8687"># DINOv2 訓練主循環：通過學生-教師架構進行自監督學習</span>
</span></span><span style="display:flex;"><span><span style="color:#8d8687"># 目標：讓學生模型學習教師模型的圖像表示，無需標籤</span>
</span></span><span style="display:flex;"><span><span style="color:#815ba4">for</span> data <span style="color:#5bc4bf">in</span> metric_logger<span style="color:#5bc4bf">.</span>log_every(data_loader, <span style="color:#f99b15">10</span>, <span style="color:#48b685">&#34;Training&#34;</span>, max_iter, start_iter):
</span></span><span style="display:flex;"><span>    <span style="color:#8d8687"># 從資料載入器獲取預處理的圖像批次（包含全局和局部裁剪）</span>
</span></span><span style="display:flex;"><span>    current_batch_size <span style="color:#5bc4bf">=</span> data[<span style="color:#48b685">&#34;collated_global_crops&#34;</span>]<span style="color:#5bc4bf">.</span>shape[<span style="color:#f99b15">0</span>] <span style="color:#5bc4bf">/</span> <span style="color:#f99b15">2</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#8d8687"># 動態調整學習率和教師模型參數（如動量和溫度）</span>
</span></span><span style="display:flex;"><span>    lr <span style="color:#5bc4bf">=</span> lr_schedule[iteration]                <span style="color:#8d8687"># 學習率</span>
</span></span><span style="display:flex;"><span>    mom <span style="color:#5bc4bf">=</span> momentum_schedule[iteration]         <span style="color:#8d8687"># 教師模型的動量</span>
</span></span><span style="display:flex;"><span>    teacher_temp <span style="color:#5bc4bf">=</span> teacher_temp_schedule[iteration]  <span style="color:#8d8687"># 教師模型的softmax溫度</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#8d8687"># 前向傳播：學生模型和教師模型處理圖像，計算損失</span>
</span></span><span style="display:flex;"><span>    <span style="color:#8d8687"># 損失包括 DINO 對比損失（匹配學生-教師輸出）和 iBOT 遮罩重建損失</span>
</span></span><span style="display:flex;"><span>    loss_dict <span style="color:#5bc4bf">=</span> model<span style="color:#5bc4bf">.</span>forward_backward(data, teacher_temp<span style="color:#5bc4bf">=</span>teacher_temp)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#8d8687"># 更新學生模型參數，根據損失調整權重</span>
</span></span><span style="display:flex;"><span>    optimizer<span style="color:#5bc4bf">.</span>step()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#8d8687"># 使用指數移動平均 (EMA) 更新教師模型，使其平滑跟隨學生模型</span>
</span></span><span style="display:flex;"><span>    model<span style="color:#5bc4bf">.</span>update_teacher(mom)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#8d8687"># 處理損失值（例如平均化），用於監控訓練進度</span>
</span></span><span style="display:flex;"><span>    <span style="color:#8d8687"># loss_dict_reduced = {k: v.item() / distributed.get_global_size() for k, v in loss_dict.items()}</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#8d8687"># 迭代計數器加 1，進入下一次迭代</span>
</span></span><span style="display:flex;"><span>    iteration <span style="color:#5bc4bf">+=</span> <span style="color:#f99b15">1</span>
</span></span></code></pre></div><p><img src="https://raw.githubusercontent.com/hamhuo-hub/HamPic/img/20250507002140296.png" alt="Pasted image 20250506075202">
其中的前項和損失計算代碼如下（精簡）</p>
<div class="highlight"><pre tabindex="0" style="color:#2f1e2e;background-color:#e7e9db;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#815ba4">def</span> <span style="color:#06b6ef">forward_backward</span>(self, images, teacher_temp):
</span></span><span style="display:flex;"><span>    <span style="color:#8d8687"># 提取全局裁剪（global crops）和局部裁剪（local crops）圖像</span>
</span></span><span style="display:flex;"><span>    global_crops <span style="color:#5bc4bf">=</span> images[<span style="color:#48b685">&#34;collated_global_crops&#34;</span>]<span style="color:#5bc4bf">.</span>cuda()  <span style="color:#8d8687"># 兩張大視圖，全局</span>
</span></span><span style="display:flex;"><span>    local_crops <span style="color:#5bc4bf">=</span> images[<span style="color:#48b685">&#34;collated_local_crops&#34;</span>]<span style="color:#5bc4bf">.</span>cuda()   <span style="color:#8d8687"># 多張小視圖，局部</span>
</span></span><span style="display:flex;"><span>    masks <span style="color:#5bc4bf">=</span> images[<span style="color:#48b685">&#34;collated_masks&#34;</span>]<span style="color:#5bc4bf">.</span>cuda()               <span style="color:#8d8687"># 遮罩，用於 iBOT 損失</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#8d8687"># 教師模型前向傳播（無梯度）：處理全局裁剪，生成參考輸出</span>
</span></span><span style="display:flex;"><span>    <span style="color:#815ba4">with</span> torch<span style="color:#5bc4bf">.</span>no_grad():
</span></span><span style="display:flex;"><span>        teacher_output <span style="color:#5bc4bf">=</span> self<span style="color:#5bc4bf">.</span>teacher<span style="color:#5bc4bf">.</span>backbone(global_crops, is_training<span style="color:#5bc4bf">=</span><span style="color:#815ba4">True</span>)
</span></span><span style="display:flex;"><span>        teacher_cls_tokens <span style="color:#5bc4bf">=</span> teacher_output[<span style="color:#48b685">&#34;x_norm_clstoken&#34;</span>]  <span style="color:#8d8687"># CLS 標記，用於 DINO 損失。可以看作全局特徵提取器</span>
</span></span><span style="display:flex;"><span>        teacher_patch_tokens <span style="color:#5bc4bf">=</span> teacher_output[<span style="color:#48b685">&#34;x_norm_patchtokens&#34;</span>]  <span style="color:#8d8687"># Patch 標記，用於 iBOT 損失</span>
</span></span><span style="display:flex;"><span>        <span style="color:#8d8687"># 對教師輸出應用 中心化和softmax概率，準備損失計算</span>
</span></span><span style="display:flex;"><span>        teacher_cls_tokens <span style="color:#5bc4bf">=</span> self<span style="color:#5bc4bf">.</span>dino_loss<span style="color:#5bc4bf">.</span>softmax_center_teacher(teacher_cls_tokens, teacher_temp)
</span></span><span style="display:flex;"><span>        teacher_patch_tokens <span style="color:#5bc4bf">=</span> self<span style="color:#5bc4bf">.</span>ibot_patch_loss<span style="color:#5bc4bf">.</span>softmax_center_teacher(teacher_patch_tokens, teacher_temp)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#8d8687"># 學生模型前向傳播：處理全局和局部裁剪，生成預測</span>
</span></span><span style="display:flex;"><span>    student_output <span style="color:#5bc4bf">=</span> self<span style="color:#5bc4bf">.</span>student<span style="color:#5bc4bf">.</span>backbone([global_crops, local_crops], masks<span style="color:#5bc4bf">=</span>[masks, <span style="color:#815ba4">None</span>], is_training<span style="color:#5bc4bf">=</span><span style="color:#815ba4">True</span>)
</span></span><span style="display:flex;"><span>    student_global_cls <span style="color:#5bc4bf">=</span> student_output[<span style="color:#f99b15">0</span>][<span style="color:#48b685">&#34;x_norm_clstoken&#34;</span>]  <span style="color:#8d8687"># 全局裁剪的 CLS 標記</span>
</span></span><span style="display:flex;"><span>    student_local_cls <span style="color:#5bc4bf">=</span> student_output[<span style="color:#f99b15">1</span>][<span style="color:#48b685">&#34;x_norm_clstoken&#34;</span>]   <span style="color:#8d8687"># 局部裁剪的 CLS 標記</span>
</span></span><span style="display:flex;"><span>    student_patch_tokens <span style="color:#5bc4bf">=</span> student_output[<span style="color:#f99b15">0</span>][<span style="color:#48b685">&#34;x_norm_patchtokens&#34;</span>]  <span style="color:#8d8687"># 全局裁剪的 Patch 標記</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#8d8687"># 初始化損失字典和累積器</span>
</span></span><span style="display:flex;"><span>    loss_dict <span style="color:#5bc4bf">=</span> {}
</span></span><span style="display:flex;"><span>    total_loss <span style="color:#5bc4bf">=</span> <span style="color:#f99b15">0</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#8d8687"># 計算 DINO 損失：讓學生模型的 CLS 標記匹配教師模型的 CLS 標記</span>
</span></span><span style="display:flex;"><span>    <span style="color:#815ba4">if</span> self<span style="color:#5bc4bf">.</span>do_dino:
</span></span><span style="display:flex;"><span>        dino_loss <span style="color:#5bc4bf">=</span> self<span style="color:#5bc4bf">.</span>dino_loss(student_global_cls, teacher_cls_tokens)  <span style="color:#8d8687"># 全局裁剪損失</span>
</span></span><span style="display:flex;"><span>        <span style="color:#815ba4">if</span> local_crops <span style="color:#5bc4bf">is</span> <span style="color:#5bc4bf">not</span> <span style="color:#815ba4">None</span>:
</span></span><span style="display:flex;"><span>            dino_loss <span style="color:#5bc4bf">+=</span> self<span style="color:#5bc4bf">.</span>dino_loss(student_local_cls, teacher_cls_tokens)  <span style="color:#8d8687"># 局部裁剪損失</span>
</span></span><span style="display:flex;"><span>        loss_dict[<span style="color:#48b685">&#34;dino_loss&#34;</span>] <span style="color:#5bc4bf">=</span> dino_loss
</span></span><span style="display:flex;"><span>        total_loss <span style="color:#5bc4bf">+=</span> self<span style="color:#5bc4bf">.</span>dino_loss_weight <span style="color:#5bc4bf">*</span> dino_loss
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#8d8687"># 計算 iBOT 損失：讓學生模型重建被遮罩的 patch 標記</span>
</span></span><span style="display:flex;"><span>    <span style="color:#815ba4">if</span> self<span style="color:#5bc4bf">.</span>do_ibot:
</span></span><span style="display:flex;"><span>        ibot_loss <span style="color:#5bc4bf">=</span> self<span style="color:#5bc4bf">.</span>ibot_patch_loss(student_patch_tokens, teacher_patch_tokens, masks)
</span></span><span style="display:flex;"><span>        loss_dict[<span style="color:#48b685">&#34;ibot_loss&#34;</span>] <span style="color:#5bc4bf">=</span> ibot_loss
</span></span><span style="display:flex;"><span>        total_loss <span style="color:#5bc4bf">+=</span> self<span style="color:#5bc4bf">.</span>ibot_loss_weight <span style="color:#5bc4bf">*</span> ibot_loss
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#8d8687"># 反向傳播：根據總損失更新學生模型參數</span>
</span></span><span style="display:flex;"><span>    self<span style="color:#5bc4bf">.</span>backprop_loss(total_loss)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#815ba4">return</span> loss_dict
</span></span></code></pre></div><h4 id="sd-dino">SD-DINO</h4>
<p><em><strong>”一個畫龍點睛，一個精雕細琢 “</strong></em>
<a href="https://arxiv.org/abs/2305.15347">A Tale of Two Features: Stable Diffusion Complements DINO for Zero-Shot Semantic Correspondence</a></p>
<h5 id="stable-diffusion穩定擴散模型sd">stable-diffusion（穩定擴散模型/SD）</h5>
<blockquote>
<p>SD通過在潛在空間（latent space）中進行擴散過程，能高效生成高質量圖像。與傳統擴散模型直接操作像素空間不同，Stable Diffusion 先將圖像壓縮到低維潛在表示，然後在潛在空間中進行去噪，從而降低計算成本並保持生成質量。</p></blockquote>
<ul>
<li><strong>擴散過程</strong>：
<ul>
<li>訓練階段：模型從真實圖像開始，逐步添加高斯噪聲，生成一系列越來越噪聲的版本（前向過程）。</li>
<li>生成階段：模型從純噪聲開始，通過學習到的去噪網絡（通常是 U-Net 架構）逐步還原圖像（反向過程）。</li>
</ul>
</li>
<li><strong>潛在空間</strong>：
<ul>
<li>使用預訓練的自動編碼器（Autoencoder）將圖像壓縮到潛在空間，減少計算量。</li>
<li>去噪過程在潛在空間進行，最後解碼回像素空間，生成高解析度圖像。</li>
</ul>
</li>
<li><strong>條件生成</strong>：
<ul>
<li>Stable Diffusion 支援條件輸入（如文字描述、圖像提示），通過交叉注意力（Cross-Attention）機制將文字或圖像信息融入生成過程，實現“文生圖”或“圖生圖”。</li>
</ul>
</li>
</ul>
<p>文本-圖像的生成模型（下文代指SD）有效地将文本提示与图像中的内容联系起来，因此它们应该能够理解图像中包含的内容。並且可以生成特定场景并对对象的布局和位置有一定程度的控制 ，所以它们应该能够定位对象並能夠實現語義分割</p>
<p><img src="https://raw.githubusercontent.com/hamhuo-hub/HamPic/img/20250507002140304.png" alt="Pasted image 20250506211934"></p>
<blockquote>
<p><em>語義分割</em>，<em>不同顏色代表不同部分</em></p></blockquote>
<p>SD-DINO 將SD特徵和DINO特徵簡單組合，通过语义对应关系（一项经典的视觉任务，旨在连接两幅或多幅图像中的相似像素）来研究稳定扩散 (SD) 特征。得到結論：SD 特征与现有的表示学习特征（例如最近发布的 DINOv2）相比具有非常不同的特性：DINOv2 提供稀疏但准确的匹配，而 SD 特征提供高质量的空间信息，但有时==语义匹配==不准确。</p>
<p><img src="https://raw.githubusercontent.com/hamhuo-hub/HamPic/img/20250507002140305.png" alt="Pasted image 20250506213326"></p>
<blockquote>
<p><em>DINO和SD特徵的權重圖</em>，最左側的身體部位連續且噪點很少，但是位置不對（==高質量的空間信息==）。最有側雖然位置精確但是噪點很多不連續（==稀疏但準確的匹配==）。</p></blockquote>
<h5 id="特徵檢測和特徵匹配">特徵檢測和特徵匹配</h5>
<p>稠密</p>
<blockquote>
<p>计算一幅图像的一个小窗口函数，窗口内的像素与另一幅图像中具有同样的潜在对应特征的大小窗函数的像素之间的相关值，具有最大相关性的小窗口区域就是对应区域</p></blockquote>
<p>簡單說就是像素與像素之間的對應
<img src="https://raw.githubusercontent.com/hamhuo-hub/HamPic/img/20250507002140306.png" alt="Pasted image 20250506161051"></p>
<p>稀疏</p>
<blockquote>
<p>基于特征（点、线）的匹配称作稀疏匹配。<br>
在立体图像对中识别兴趣点而后在两幅图像中匹配相对应的点。</p></blockquote>
<p>簡單說就是基於較大部分（部位）的匹配，不再關注具體的像素值
<img src="https://raw.githubusercontent.com/hamhuo-hub/HamPic/img/20250507002140307.png" alt="Pasted image 20250506161406"></p>
<h4 id="代碼部分精簡">代碼部分（精簡）</h4>
<div class="highlight"><pre tabindex="0" style="color:#2f1e2e;background-color:#e7e9db;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#815ba4">def</span> <span style="color:#06b6ef">compute_pair_feature</span>(model, files, category, dist<span style="color:#5bc4bf">=</span><span style="color:#48b685">&#39;cos&#39;</span>, img_size<span style="color:#5bc4bf">=</span><span style="color:#f99b15">840</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#48b685">&#34;&#34;&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#48b685">    為一對圖像提取 DINOv2 和 Stable Diffusion 特徵，用於語義對應任務。
</span></span></span><span style="display:flex;"><span><span style="color:#48b685">    返回特徵描述，支援 SD（全局語義）和 DINOv2（局部精確）的融合。
</span></span></span><span style="display:flex;"><span><span style="color:#48b685">    &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    device <span style="color:#5bc4bf">=</span> <span style="color:#48b685">&#39;cuda&#39;</span> <span style="color:#815ba4">if</span> torch<span style="color:#5bc4bf">.</span>cuda<span style="color:#5bc4bf">.</span>is_available() <span style="color:#815ba4">else</span> <span style="color:#48b685">&#39;cpu&#39;</span>
</span></span><span style="display:flex;"><span>    extractor <span style="color:#5bc4bf">=</span> ViTExtractor(<span style="color:#48b685">&#39;dinov2_vitb14&#39;</span>, stride<span style="color:#5bc4bf">=</span><span style="color:#f99b15">14</span>, device<span style="color:#5bc4bf">=</span>device)  <span style="color:#8d8687"># 初始化 DINOv2 模型</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    result <span style="color:#5bc4bf">=</span> []
</span></span><span style="display:flex;"><span>    <span style="color:#815ba4">for</span> pair_idx <span style="color:#5bc4bf">in</span> range(len(files) <span style="color:#5bc4bf">//</span> <span style="color:#f99b15">2</span>):
</span></span><span style="display:flex;"><span>        <span style="color:#8d8687"># 載入並預處理圖像對</span>
</span></span><span style="display:flex;"><span>        img1 <span style="color:#5bc4bf">=</span> Image<span style="color:#5bc4bf">.</span>open(files[<span style="color:#f99b15">2</span> <span style="color:#5bc4bf">*</span> pair_idx])<span style="color:#5bc4bf">.</span>convert(<span style="color:#48b685">&#39;RGB&#39;</span>)
</span></span><span style="display:flex;"><span>        img2 <span style="color:#5bc4bf">=</span> Image<span style="color:#5bc4bf">.</span>open(files[<span style="color:#f99b15">2</span> <span style="color:#5bc4bf">*</span> pair_idx <span style="color:#5bc4bf">+</span> <span style="color:#f99b15">1</span>])<span style="color:#5bc4bf">.</span>convert(<span style="color:#48b685">&#39;RGB&#39;</span>)
</span></span><span style="display:flex;"><span>        img1 <span style="color:#5bc4bf">=</span> resize(img1, img_size, resize<span style="color:#5bc4bf">=</span><span style="color:#815ba4">True</span>, to_pil<span style="color:#5bc4bf">=</span><span style="color:#815ba4">True</span>)
</span></span><span style="display:flex;"><span>        img2 <span style="color:#5bc4bf">=</span> resize(img2, img_size, resize<span style="color:#5bc4bf">=</span><span style="color:#815ba4">True</span>, to_pil<span style="color:#5bc4bf">=</span><span style="color:#815ba4">True</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#815ba4">with</span> torch<span style="color:#5bc4bf">.</span>no_grad():
</span></span><span style="display:flex;"><span>            <span style="color:#8d8687"># 提取 Stable Diffusion 特徵（全局語義）</span>
</span></span><span style="display:flex;"><span>            img1_sd <span style="color:#5bc4bf">=</span> process_features(model, img1, category<span style="color:#5bc4bf">=</span>category[<span style="color:#5bc4bf">-</span><span style="color:#f99b15">1</span>])
</span></span><span style="display:flex;"><span>            img2_sd <span style="color:#5bc4bf">=</span> process_features(model, img2, category<span style="color:#5bc4bf">=</span>category[<span style="color:#5bc4bf">-</span><span style="color:#f99b15">1</span>])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>            <span style="color:#8d8687"># 提取 DINOv2 特徵（局部結構）</span>
</span></span><span style="display:flex;"><span>            img1_batch <span style="color:#5bc4bf">=</span> extractor<span style="color:#5bc4bf">.</span>preprocess_pil(img1)
</span></span><span style="display:flex;"><span>            img1_dino <span style="color:#5bc4bf">=</span> extractor<span style="color:#5bc4bf">.</span>extract_descriptors(img1_batch<span style="color:#5bc4bf">.</span>to(device), layer<span style="color:#5bc4bf">=</span><span style="color:#f99b15">11</span>, facet<span style="color:#5bc4bf">=</span><span style="color:#48b685">&#39;token&#39;</span>)
</span></span><span style="display:flex;"><span>            img2_batch <span style="color:#5bc4bf">=</span> extractor<span style="color:#5bc4bf">.</span>preprocess_pil(img2)
</span></span><span style="display:flex;"><span>            img2_dino <span style="color:#5bc4bf">=</span> extractor<span style="color:#5bc4bf">.</span>extract_descriptors(img2_batch<span style="color:#5bc4bf">.</span>to(device), layer<span style="color:#5bc4bf">=</span><span style="color:#f99b15">11</span>, facet<span style="color:#5bc4bf">=</span><span style="color:#48b685">&#39;token&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>            <span style="color:#8d8687"># 融合 SD 和 DINOv2 特徵，增強語義對應</span>
</span></span><span style="display:flex;"><span>            img1_desc <span style="color:#5bc4bf">=</span> torch<span style="color:#5bc4bf">.</span>cat((img1_sd, img1_dino), dim<span style="color:#5bc4bf">=-</span><span style="color:#f99b15">1</span>)
</span></span><span style="display:flex;"><span>            img2_desc <span style="color:#5bc4bf">=</span> torch<span style="color:#5bc4bf">.</span>cat((img2_sd, img2_dino), dim<span style="color:#5bc4bf">=-</span><span style="color:#f99b15">1</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>            <span style="color:#8d8687"># 正規化特徵，準備相似性計算</span>
</span></span><span style="display:flex;"><span>            <span style="color:#815ba4">if</span> dist <span style="color:#5bc4bf">in</span> [<span style="color:#48b685">&#39;l1&#39;</span>, <span style="color:#48b685">&#39;l2&#39;</span>]:
</span></span><span style="display:flex;"><span>                img1_desc <span style="color:#5bc4bf">=</span> img1_desc <span style="color:#5bc4bf">/</span> img1_desc<span style="color:#5bc4bf">.</span>norm(dim<span style="color:#5bc4bf">=-</span><span style="color:#f99b15">1</span>, keepdim<span style="color:#5bc4bf">=</span><span style="color:#815ba4">True</span>)
</span></span><span style="display:flex;"><span>                img2_desc <span style="color:#5bc4bf">=</span> img2_desc <span style="color:#5bc4bf">/</span> img2_desc<span style="color:#5bc4bf">.</span>norm(dim<span style="color:#5bc4bf">=-</span><span style="color:#f99b15">1</span>, keepdim<span style="color:#5bc4bf">=</span><span style="color:#815ba4">True</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#8d8687"># 儲存特徵描述，供語義對應使用</span>
</span></span><span style="display:flex;"><span>        result<span style="color:#5bc4bf">.</span>append([img1_desc<span style="color:#5bc4bf">.</span>cpu(), img2_desc<span style="color:#5bc4bf">.</span>cpu()])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#815ba4">return</span> result
</span></span></code></pre></div><p><img src="https://cdn.jsdelivr.net/gh/hamhuo-hub/HamPic@img/img/20250507035701951.gif" alt="1_swap.gif"></p>
<blockquote>
<p><em>飞机的特征匹配</em>，<em>效果一般</em></p></blockquote>
<p><img src="https://cdn.jsdelivr.net/gh/hamhuo-hub/HamPic@img/img/20250507035749002.png" alt="0_pred.png"></p>
<blockquote>
<p><em>飞机的稀疏匹配</em></p></blockquote>

	<div class="td-page-meta__lastmod">
  Last modified May 13, 2025: <a data-proofer-ignore href="https://github.com/google/docsy-example/commit/186c7d5fd01e2287e503de925d40c649085de98e">update index (186c7d5)</a>
</div>

</div>


          </main>
        </div>
      </div>
      <footer class="td-footer row d-print-none">
  <div class="container-fluid">
    <div class="row mx-md-2">
      <div class="td-footer__left col-6 col-sm-4 order-sm-1">
        <ul class="td-footer__links-list">
  
  <li class="td-footer__links-item" data-bs-toggle="tooltip" title="User mailing list" aria-label="User mailing list">
    <a target="_blank" rel="noopener" href="https://example.org/mail" aria-label="User mailing list">
      <i class="fa fa-envelope"></i>
    </a>
  </li>
  
  <li class="td-footer__links-item" data-bs-toggle="tooltip" title="Twitter" aria-label="Twitter">
    <a target="_blank" rel="noopener" href="https://example.org/twitter" aria-label="Twitter">
      <i class="fab fa-twitter"></i>
    </a>
  </li>
  
  <li class="td-footer__links-item" data-bs-toggle="tooltip" title="Stack Overflow" aria-label="Stack Overflow">
    <a target="_blank" rel="noopener" href="https://example.org/stack" aria-label="Stack Overflow">
      <i class="fab fa-stack-overflow"></i>
    </a>
  </li>
  
</ul>

      </div><div class="td-footer__right col-6 col-sm-4 order-sm-3">
        <ul class="td-footer__links-list">
  
  <li class="td-footer__links-item" data-bs-toggle="tooltip" title="GitHub" aria-label="GitHub">
    <a target="_blank" rel="noopener" href="https://github.com/google/docsy" aria-label="GitHub">
      <i class="fab fa-github"></i>
    </a>
  </li>
  
  <li class="td-footer__links-item" data-bs-toggle="tooltip" title="Slack" aria-label="Slack">
    <a target="_blank" rel="noopener" href="https://example.org/slack" aria-label="Slack">
      <i class="fab fa-slack"></i>
    </a>
  </li>
  
  <li class="td-footer__links-item" data-bs-toggle="tooltip" title="Developer mailing list" aria-label="Developer mailing list">
    <a target="_blank" rel="noopener" href="https://example.org/mail" aria-label="Developer mailing list">
      <i class="fa fa-envelope"></i>
    </a>
  </li>
  
</ul>

      </div><div class="td-footer__center col-12 col-sm-4 py-2 order-sm-2">
        <span class="td-footer__copyright">&copy;
    2024&ndash;2025
    <span class="td-footer__authors">Hamhuo Authors | <a href="https://creativecommons.org/licenses/by/4.0">CC BY 4.0</a> |</span></span><span class="td-footer__all_rights_reserved">All Rights Reserved</span><span class="ms-2"><a href="https://policies.google.com/privacy" target="_blank" rel="noopener">Privacy Policy</a></span>
      </div>
    </div>
  </div>
</footer>

    </div>
    <script src="/js/main.min.d8fd71c60234beffac13dd75ea2a5ce1133a205f46fc7501ba538f3910c313ff.js" integrity="sha256-2P1xxgI0vv&#43;sE9116ipc4RM6IF9G/HUBulOPORDDE/8=" crossorigin="anonymous"></script>
<script defer src="/js/click-to-copy.min.73478a7d4807698aed7e355eb23f9890ca18fea3158604c8471746d046702bad.js" integrity="sha256-c0eKfUgHaYrtfjVesj&#43;YkMoY/qMVhgTIRxdG0EZwK60=" crossorigin="anonymous"></script>
<script src='/js/tabpane-persist.js'></script>

  </body>
</html>